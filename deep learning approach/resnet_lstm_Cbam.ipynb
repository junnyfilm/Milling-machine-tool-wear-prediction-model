{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "881bcb97-5aa3-46a7-befe-e9c887093687",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# load dataset and show the first run\n",
    "case1run1 = pd.read_csv('./mill_data/case1run1.csv')\n",
    "case1run2 = pd.read_csv('./mill_data/case1run2.csv')\n",
    "columns=['case', 'run', 'VB', 'time', 'doc','feed','material','smcAC', 'smcDC', 'vib_table', 'vib_spindle', 'AE_table', 'AE_spindle']\n",
    "case1run1.columns = columns\n",
    "case1run2.columns = columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e3c5f263-0eaf-449e-891d-d5efd1471592",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import dask.dataframe as dd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn import preprocessing, metrics\n",
    "from ipywidgets import widgets, interactive\n",
    "import gc\n",
    "import joblib\n",
    "import glob\n",
    "import os\n",
    "import warnings\n",
    "from datetime import datetime, timedelta\n",
    "from typing import Union\n",
    "from tqdm.notebook import tqdm_notebook as tqdm\n",
    "from itertools import cycle\n",
    "import datetime as dt\n",
    "from torch.autograd import Variable\n",
    "import random\n",
    "from matplotlib.pyplot import figure\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from copy import deepcopy\n",
    "from torch.utils.data import Dataset\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_rows', 500)\n",
    "from scipy.signal import hilbert, chirp\n",
    "\n",
    "from resnet_lstm_cbam import cbam_ResNet_lstm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5ba8a844-455e-4c4f-a852-273f8ff20d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sliding_windows(data):\n",
    "    x = []\n",
    "    for i in range(int((len(data)-512)/100)):\n",
    "        _x = data[i*100:i*100+512]\n",
    "        x.append(_x)\n",
    "    x=np.array(x)\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf0ad3e-b6a3-4f22-a46f-fecf80294099",
   "metadata": {},
   "outputs": [],
   "source": [
    "def labeling(data,lab):\n",
    "    x = []\n",
    "    for i in range(int((len(data)-512)/100)):\n",
    "        _x = data[i*100:i*100+512]\n",
    "        x.append(lab)\n",
    "\n",
    "    return np.array(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1020d037-0510-49ec-8da8-2ba9e56b4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "path1 = './mill_data/train/'\n",
    "path2 = './mill_data/test/'\n",
    "\n",
    "file_list1 = os.listdir(path1)\n",
    "file_list2 = os.listdir(path2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "3e96773a-a110-4d7c-8d30-e85c6f28691a",
   "metadata": {},
   "outputs": [],
   "source": [
    "fs = 100000\n",
    "def hibert_transform(data):\n",
    "    analytic_signal = hilbert(data)\n",
    "    amplitude_envelope = np.abs(analytic_signal)\n",
    "    instantaneous_phase = np.unwrap(np.angle(analytic_signal))\n",
    "    instantaneous_frequency = (np.diff(instantaneous_phase) /(2.0*np.pi) * fs)\n",
    "    return amplitude_envelope,instantaneous_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a8a29ad-d33c-47e1-9827-e3293d5ebda3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_dataset(data,label):\n",
    "    smcAC=np.expand_dims(sliding_windows(data['smcAC'][2000:-2000]),axis=2)\n",
    "    evelop,ins_freq=hibert_transform(data['smcAC'][2000:-2000])\n",
    "    evelop_d=np.expand_dims(sliding_windows(evelop),axis=2)\n",
    "    ins_freq_d=np.expand_dims(sliding_windows(ins_freq),axis=2)\n",
    "\n",
    "    # smcDC=np.expand_dims(sliding_windows(data['smcDC'][3000:-3000],4),axis=2)\n",
    "    vib_table=np.expand_dims(sliding_windows(data['vib_table'][2000:-2000]),axis=2)\n",
    "    vib_spindle=np.expand_dims(sliding_windows(data['vib_spindle'][2000:-2000]),axis=2)\n",
    "    AE_table=np.expand_dims(sliding_windows(data['AE_table'][2000:-2000]),axis=2)\n",
    "    AE_spindle=np.expand_dims(sliding_windows(data['AE_spindle'][2000:-2000]),axis=2)\n",
    "    xdata = np.concatenate((smcAC,vib_table,vib_spindle,AE_table,AE_spindle,evelop_d,ins_freq_d),axis=2)\n",
    "    ydata = labeling(data[2000:-2000], label)\n",
    "\n",
    "    return xdata,ydata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0b760e05-7b63-4ea0-8eeb-0d25a6d7ef53",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_casedataset_tr(data_list):\n",
    "    empty_x=np.zeros(((1, 512, 7)))\n",
    "    empty_y=np.zeros(((1)))\n",
    "\n",
    "    for i in data_list:\n",
    "        pdd=pd.read_csv('./mill_data/train/'+i)\n",
    "        pdd.columns = columns\n",
    "        lab=pdd['VB'][0]\n",
    "        if str(lab)!='nan':\n",
    "            x_,y_=to_dataset(pdd,lab)\n",
    "            empty_x=np.concatenate((empty_x,x_),axis=0)\n",
    "            empty_y=np.concatenate((empty_y,y_),axis=0)\n",
    "    empty_x=np.transpose(empty_x[1:],(0,2,1))\n",
    "\n",
    "    return empty_x,empty_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c5232a94-c224-4a78-b68f-6e87278967a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_casedataset_ts(data_list):\n",
    "    empty_x=np.zeros(((1, 512, 7)))\n",
    "    empty_y=np.zeros(((1)))\n",
    "\n",
    "    for i in data_list:\n",
    "        pdd=pd.read_csv('./mill_data/test/'+i)\n",
    "        pdd.columns = columns\n",
    "        lab=pdd['VB'][0]\n",
    "        if str(lab)!='nan':\n",
    "            x_,y_=to_dataset(pdd,lab)\n",
    "            empty_x=np.concatenate((empty_x,x_),axis=0)\n",
    "            empty_y=np.concatenate((empty_y,y_),axis=0)\n",
    "    empty_x=np.transpose(empty_x[1:],(0,2,1))\n",
    "\n",
    "    return empty_x,empty_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e8a97352-5ac8-458a-b0f0-411be374d1d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "case1list=[file for file in file_list1 if file.startswith('case')]\n",
    "case9list=[file for file in file_list2 if file.startswith('case9')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "65e3de64-a663-4f3e-9f86-105c185fb8c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_x,c1_y=to_casedataset_tr(case1list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "72d02613-1cb9-457c-b513-9f525c37a5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "c9_x,c9_y=to_casedataset_ts(case9list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "164bb1ca-5129-439f-a002-f379d5108efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SequenceDataset(Dataset):\n",
    "    def __init__(self, x, y):\n",
    "        self.x=x\n",
    "        self.y=y\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.x.shape[0]\n",
    "\n",
    "    def __getitem__(self, i): \n",
    "        data=self.x[i]\n",
    "        label=self.y[i]\n",
    "\n",
    "        return data,label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7698ce77-5604-4f95-b304-3270a4b72874",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train shape is: torch.Size([2068, 7, 512])\n",
      "train label shape is: torch.Size([2068])\n",
      "test shape is: torch.Size([396, 7, 512])\n",
      "test label shape is: torch.Size([396])\n"
     ]
    }
   ],
   "source": [
    "c1_x = Variable(torch.Tensor(np.array(c1_x)))\n",
    "c1_y = Variable(torch.Tensor(np.array(c1_y)))\n",
    "c9_x = Variable(torch.Tensor(np.array(c9_x)))\n",
    "c9_y = Variable(torch.Tensor(np.array(c9_y)))\n",
    "\n",
    "\n",
    "print(\"train shape is:\",c1_x.size())\n",
    "print(\"train label shape is:\",c1_y.size())\n",
    "print(\"test shape is:\",c9_x.size())\n",
    "print(\"test label shape is:\",c9_y.size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f2be31f-4be8-4e86-bdff-4f9dc90b1457",
   "metadata": {},
   "outputs": [],
   "source": [
    "c1_dataset=SequenceDataset(c1_x,c1_y)\n",
    "c9_dataset=SequenceDataset(c9_x,c9_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2d6d9cd8-6f69-4279-b6dd-f759e36da77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(99)\n",
    "\n",
    "train_loader = DataLoader(c1_dataset, batch_size=32, shuffle=True)\n",
    "test_loader = DataLoader(c9_dataset, batch_size=1, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "6ed2a4f5-6f89-43d3-a1f0-0867730a3208",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 1e-3\n",
    "# num_hidden_units = 4\n",
    "epochs = 50\n",
    "model = cbam_ResNet_lstm(BasicBlock, [2, 2, 2, 2])\n",
    "loss_function = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "a61e2bca-6139-4521-bd18-cdd4b0398527",
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "def train_model(data_loader, model, loss_function, optimizer):\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "    model.train()\n",
    "\n",
    "    for X, y in data_loader:\n",
    "        output = model(X)\n",
    "        loss = torch.sqrt(loss_function(output, y))\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss\n",
    "\n",
    "def test_model(data_loader, model, loss_function):\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += torch.sqrt(loss_function(output, y)).item()\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "6424f056-013b-46bf-84d0-ef462e0cc06f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untrained test\n",
      "0.21377789586631937\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(\"Untrained test\")\n",
    "print(test_model(test_loader, model, loss_function))\n",
    "best_fitness = -100000\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "9aa40908-00fd-46bd-ab54-a6d6de75a107",
   "metadata": {},
   "outputs": [],
   "source": [
    "scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs',min_lr=1e-8, verbose=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41f04c1-a1c2-4761-8111-4436a72ffb1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "run: 0\n",
      "train_loss: 0.1416539456981879\n",
      "test_loss: 0.20886810981866086\n",
      "run: 1\n",
      "train_loss: 0.14061608750086566\n",
      "test_loss: 0.2086678066036918\n",
      "run: 2\n",
      "train_loss: 0.14056312132340212\n",
      "test_loss: 0.2082288899656498\n",
      "run: 3\n",
      "train_loss: 0.14055488705635072\n",
      "test_loss: 0.2087863405997103\n",
      "run: 4\n",
      "train_loss: 0.1403837536390011\n",
      "test_loss: 0.2083234034403406\n",
      "run: 5\n",
      "train_loss: 0.1405871768410389\n",
      "test_loss: 0.20812203441605423\n",
      "run: 6\n",
      "train_loss: 0.14063247052522806\n",
      "test_loss: 0.20807502486489035\n",
      "run: 7\n",
      "train_loss: 0.14006182906719356\n",
      "test_loss: 0.20844225374737171\n",
      "run: 8\n",
      "train_loss: 0.14066043484669466\n",
      "test_loss: 0.2078573229638013\n",
      "run: 9\n",
      "train_loss: 0.1406086374933903\n",
      "test_loss: 0.20868051277868677\n",
      "run: 10\n",
      "train_loss: 0.14062879360639133\n",
      "test_loss: 0.2086037141506118\n",
      "run: 11\n",
      "train_loss: 0.14088000471775347\n",
      "test_loss: 0.2083182077516209\n",
      "Epoch 00012: reducing learning rate of group 0 to 5.0000e-04.\n",
      "run: 12\n",
      "train_loss: 0.14071000482027346\n",
      "test_loss: 0.20839732606904676\n",
      "run: 13\n",
      "train_loss: 0.14078478721471932\n",
      "test_loss: 0.2081555381718308\n",
      "run: 14\n",
      "train_loss: 0.14069540982063\n",
      "test_loss: 0.20855713680838095\n",
      "run: 15\n",
      "train_loss: 0.14055355959213697\n",
      "test_loss: 0.20834447699363787\n",
      "run: 16\n",
      "train_loss: 0.14067002030519338\n",
      "test_loss: 0.2080152647362815\n",
      "run: 17\n",
      "train_loss: 0.1407233144228275\n",
      "test_loss: 0.20830186336028456\n",
      "run: 18\n"
     ]
    }
   ],
   "source": [
    "fig, axs = plt.subplots(1, 2)\n",
    "for epoch in range(45):\n",
    "    print(\"run:\", epoch)\n",
    "    train_loss = train_model(train_loader, model, loss_function, optimizer=optimizer)\n",
    "    test_loss = test_model(test_loader, model, loss_function)\n",
    "    print(\"train_loss:\",train_loss)\n",
    "    print(\"test_loss:\",test_loss)\n",
    "    axs[0].scatter(epoch, train_loss, color='g')\n",
    "    axs[1].scatter(epoch, test_loss, color='r')\n",
    "    fitness = -test_loss\n",
    "    scheduler.step(test_loss)\n",
    "\n",
    "    if fitness > best_fitness:\n",
    "        best_fitness = fitness\n",
    "        best_model = deepcopy(model)\n",
    "axs[0].set_yscale('log')\n",
    "axs[1].set_yscale('log')\n",
    "plt.show()\n",
    "plt.cla()\n",
    "plt.clf()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "165a5287-d1f6-4f14-a729-b1d2a95841cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model2(data_loader, model, loss_function):\n",
    "\n",
    "    num_batches = len(data_loader)\n",
    "    total_loss = 0\n",
    "\n",
    "    model.eval()\n",
    "    a=[]\n",
    "    b=[]\n",
    "    with torch.no_grad():\n",
    "        for X, y in data_loader:\n",
    "            output = model(X)\n",
    "            total_loss += torch.sqrt(loss_function(output, y)).item()\n",
    "            a.append(y)\n",
    "            b.append(output)\n",
    "\n",
    "    avg_loss = total_loss / num_batches\n",
    "    return avg_loss,a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8424b5b7-6daa-4d3e-9ff5-3920fe1334af",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(c9_dataset, batch_size=int(len(c9_dataset)/13), shuffle=False)\n",
    "print('Predictions on test set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "653b2320-0834-4fad-8229-0091b0178093",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,v,n=test_model2(test_loader, model, loss_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ffd1d-3be1-4ff2-9692-1b2b78ada8e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "q,w=[],[]\n",
    "for i in range(len(v)):\n",
    "    q.append(sum(v[i])/len(v[i]))\n",
    "    w.append(sum(n[i])/len(n[i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b48048a-1581-4944-a580-b381588d6f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(q, 'bo-',color='r')\n",
    "plt.plot(w, 'bo-',color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e55c909-826b-4c2a-9e23-fdcbddccacfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(c1_dataset, batch_size=int(len(c1_dataset)/13), shuffle=False)\n",
    "print('Predictions on train set')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e3691f-41e1-48ac-8419-adef59a23b7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "c,v,n=test_model2(train_loader, model, loss_function)\n",
    "q,w=[],[]\n",
    "for i in range(len(v)):\n",
    "    q.append(sum(v[i])/len(v[i]))\n",
    "    w.append(sum(n[i])/len(n[i]))\n",
    "    \n",
    "plt.plot(q, 'bo-',color='r')\n",
    "plt.plot(w, 'bo-',color='b')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72a6b249-2a7d-4660-a54e-8ffe9e3b7b5b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8d18d4-c802-4b3b-b913-e5921b6ca6c2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6b8c335-eb38-4e30-aca9-7012f37a16ea",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da4cc746-6dbf-4f9a-a6f1-8ac34f76605e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
